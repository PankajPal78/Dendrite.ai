# -*- coding: utf-8 -*-
"""Dendrite_ai.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OPzBksXLDdZGt4NfrIqaCZex6r1iRd4F

##**Dendrite.ai Data Science Assignment**##
"""

import pandas as pd
import numpy as np
import json

df=pd.read_csv('/content/iris.csv')
df.head()

from sklearn.preprocessing import OneHotEncoder
ohe=OneHotEncoder()
df1=pd.DataFrame(ohe.fit_transform(df[['species']]).toarray(),columns=df['species'].unique())
df=pd.concat([df,df1],axis=1)
df.drop('species', axis=1,inplace=True)

df.head()

df_json = pd.read_json('/content/algoparams.json')
df_json

import findspark
findspark.init()

import pyspark
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('Dendrite').getOrCreate()

spark

df_json_pyspark=spark.read.option("multiline","true").json("/content/algoparams.json")

display(df_json_pyspark )

df_json_pyspark.show()

df_json_pyspark.printSchema()

from pyspark.sql import DataFrame
from pyspark.sql.functions import col, explode_outer
from pyspark.sql.types import StructType, ArrayType

def flatten(df: DataFrame, verbose: bool = False) -> DataFrame:
    complex_fields = {field.name: field.dataType for field in df.schema.fields
                      if isinstance(field.dataType, (StructType, ArrayType))}

    while complex_fields:
        col_name = list(complex_fields.keys())[0]
        col_type = complex_fields[col_name]

        if verbose:
            print(f"Processing: {col_name} | Type: {type(col_type).__name__}")

        if isinstance(col_type, StructType):
            expanded_cols = [
                col(f"{col_name}.{nested.name}").alias(f"{col_name}_{nested.name}")
                for nested in col_type
            ]
            df = df.select("*", *expanded_cols).drop(col_name)

        elif isinstance(col_type, ArrayType):
            df = df.withColumn(col_name, explode_outer(col_name))

        complex_fields = {field.name: field.dataType for field in df.schema.fields
                          if isinstance(field.dataType, (StructType, ArrayType))}

    return df

df_flatten = flatten(df_json_pyspark )
df_flatten.show()

df_flatten.describe()

"""##1) Read the target and type of regression to be run.##"""

target=df_json.loc['target','design_state_data']['target']
type_of_reg=df_json.loc['target','design_state_data']['type']

target

type_of_reg

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.tree import DecisionTreeRegressor

p = df[["sepal_length", "sepal_width", "petal_length"]]
q = df["petal_width"]

p_train, p_test, q_train, q_test = train_test_split(p, q, test_size=0.2, random_state=42)

models={
    'LinearRegression':LinearRegression(),
    'Ridge':Ridge(),
    'Lasso':Lasso(),
    'ElasticNet':ElasticNet(),
    'RandomForestRegressor':RandomForestRegressor(), # Use Regressor instead of Classifier
    'GradientBoostingRegressor':GradientBoostingRegressor(), # Use Regressor instead of Classifier
    'DecisionTreeRegressor':DecisionTreeRegressor()
}

for name, model in models.items():
    model.fit(p_train, q_train)
    score = model.score(p_test, q_test)
    print(f'{name}: {score:.3f}')

"""##2) Read the features (which are column names in the csv) and figure out what missing imputation needs to be applied and apply that to the columns loaded in a dataframe.##"""

feature_dict=df_json.loc['feature_handling','design_state_data']

def feature_handling(feature_handling, column_names,df):
    for col in column_names:
        try:
            if feature_handling[col]['feature_details']['impute_with'] == 'custom':
                df[col] = df[col].fillna(feature_handling[col]['feature_details']['impute_value'])
            elif feature_handling[col]['feature_details']['impute_with'] == 'Average of values':
                df[col] = df[col].fillna(df[col].mean())
        except KeyError:
            print(col)
    return df

feature_handling(feature_dict, df.columns, df)

df_csv_pyspark = spark.read.csv('/content/iris.csv',header=True,inferSchema=True)

df_csv_pyspark.printSchema()

df_csv_pyspark.show()

df_csv_pyspark=df_csv_pyspark.drop('species')

df_csv_pyspark.show()

from pyspark.ml.feature import Imputer

imputer = Imputer(
    inputCols=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'],
    outputCols=["{}_imputed".format(c) for c in ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]
    ).setStrategy("mean")

imputer.fit(df_csv_pyspark).transform(df_csv_pyspark).show()

"""##3) Compute feature reduction based on input. See the screenshot below where there can be No Reduction, Corr with Target, Tree-based, PCA. Please make sure you write code so that all options can work. If we rerun your code with a different Json it should work if we switch No Reduction to say PCA.##"""

df = pd.read_csv('/content/iris.csv')
df

df['species'] =df['species'].astype('category').cat.codes
df.corr()

"""##Correlation matrix heatmap##"""

import seaborn as sns

sns.set(rc = {'figure.figsize':(16,8)})
sns.heatmap(df.corr(), annot = True, fmt='.2g',cmap= 'coolwarm')

from sklearn.decomposition import PCA
from sklearn.metrics import mean_squared_error
from scipy.stats import pearsonr

X = pd.DataFrame(df)
X

y = X.pop('species')
y

def no_reduction(X, y):
    return X

def corr_with_target(X, y, threshold=0.5):
    corr_with_target = X.corrwith(y).abs()
    features_to_keep = corr_with_target[corr_with_target >= threshold].index
    return X[features_to_keep]

def tree_based(X, y, n_features=3):
    model = RandomForestRegressor(n_estimators=100, random_state=0)
    model.fit(X, y)
    feature_importances = model.feature_importances_
    features_to_keep = X.columns[np.argsort(feature_importances)[::-1][:n_features]]
    return X[features_to_keep]

def pca_reduction(X, y, n_components=2):
    pca = PCA(n_components=n_components)
    X_reduced = pca.fit_transform(X)
    cols = ['PC'+str(i) for i in range(1, n_components+1)]
    X_reduced_df = pd.DataFrame(X_reduced, columns=cols, index=X.index)
    return X_reduced_df

reduction_methods = {
    'No Reduction': no_reduction,
    'Corr with Target': corr_with_target,
    'Tree-based': tree_based,
    'PCA': pca_reduction
}

selected_method = 'Corr with Target'

X_reduced = reduction_methods[selected_method](X, y)

print("Original number of features: ", X.shape[1])
print("Selected feature reduction method: ", selected_method)
print("Number of features after feature reduction: ", X_reduced.shape[1])
print("Selected features: ", X_reduced.columns)

"""
## 4) Parse the Json and make the model objects (using sklean) that can handle what is required in the “prediction_type” specified in the JSON (See 1 where “prediction_type” is specified). Keep in mind not to pick models that don’t apply for the prediction_type specified.##"""

df_json.loc['algorithms']['design_state_data']

from sklearn.metrics import mean_squared_error, r2_score

p = df[["sepal_length", "sepal_width", "petal_length"]]
q = df["petal_width"]

p_train, p_test, q_train, q_test = train_test_split(p, q, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error

# Define models in a dictionary
models = {
    "Random Forest Regressor": RandomForestRegressor(n_estimators=100, random_state=42),
    "Gradient Boosting Regressor": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42),
    "Linear Regression": LinearRegression(),
    "Ridge Regression": Ridge(alpha=1.0),
    "Lasso Regression": Lasso(alpha=0.1),
    "Elastic Net Regression": ElasticNet(alpha=0.1, l1_ratio=0.5),
    "Decision Tree Regressor": DecisionTreeRegressor()
}

# Train, predict and print MSE for each model
for name, model in models.items():
    model.fit(p_train, q_train)
    pred = model.predict(p_test)
    mse = mean_squared_error(q_test, pred)
    print(f"{name}: MSE = {mse:.4f}")

"""##5) Run the fit and predict on each model – keep in mind that you need to do hyper parameter tuning i.e., use GridSearchCV."""

from sklearn.model_selection import GridSearchCV

p_train, p_test, q_train, q_test = train_test_split(p, q, test_size=0.2, random_state=42)

models = { "Random Forest Regressor": {"model": RandomForestRegressor(), "params": {"n_estimators": [50, 100, 200], "max_features": ["sqrt", "log2"]}}, "GBT Regressor": {"model": GradientBoostingRegressor(), "params": {"n_estimators": [50, 100, 200], "learning_rate": [0.01, 0.1, 1.0], "max_depth": [3, 5, 10]}}, "Linear Regression": {"model": LinearRegression(), "params": {}}, "Ridge Regression": {"model": Ridge(), "params": {"alpha": [0.01, 0.1, 1.0, 10.0]}}, "Lasso Regression": {"model": Lasso(), "params": {"alpha": [0.01, 0.1, 1.0, 10.0]}}, "Elastic Net Regression": {"model": ElasticNet(), "params": {"alpha": [0.01, 0.1, 1.0, 10.0], "l1_ratio": [0.25, 0.5, 0.75]}}, "Decision Tree Regressor": {"model": DecisionTreeRegressor(), "params": {"max_depth": [3, 5, 10]}} }

for name, mp in models.items():
    model = GridSearchCV(mp['model'], mp['params'], cv=3, n_jobs=-1, scoring='neg_mean_squared_error')
    model.fit(p_train, q_train)
    q_pred = model.predict(p_test)
    mse = mean_squared_error(q_test, q_pred)
    r2 = r2_score(q_test, q_pred)

    print(f"--->> {name}:")
    print(f" Best Parameters: {model.best_params_}")
    print(f" Mean Squared Error: {mse:.3f}")
    print(f" R^2 Score: {r2:.3f}")
    print("_________________________________________________________________________________________________________")

RandomForestRegressor_params = {
    'model_name': 'Random Forest Regressor',
    'is_selected': True,
    'min_trees': 10,
    'max_trees': 20,
    'feature_sampling_statergy': 'Default',
    'min_depth': 20,
    'max_depth': 25,
    'min_samples_per_leaf_min_value': 5,
    'min_samples_per_leaf_max_value': 10,
    'parallelism': 0
}

rf_param_grid = {
    'n_estimators': [10, 15, 20],
    'max_depth': [20, 23, 25],
    'min_samples_leaf': [5, 7, 10]
}

rf_model = RandomForestRegressor(random_state=42)
rf_gs = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')

rf_gs.fit(df.drop(target, axis=1), df[target])

rf_best_model = rf_gs.best_estimator_

rf_preds = rf_best_model.predict(df.drop(target, axis=1))
rf_mse = mean_squared_error(df[target], rf_preds)

print("Model: Random Forest Regressor")
print("Best Parameters: ", rf_gs.best_params_)
print("MSE: ", rf_mse)
print("Predictions: ", rf_preds)
print("=" * 100)

gbt_param_grid = {
    'n_estimators': [67, 89],
    'max_depth': [5, 7],
    'learning_rate': [0.1, 0.3, 0.5],
    'subsample': [1.0, 1.5, 2.0]
}

gbt_model = GradientBoostingRegressor(random_state=42)
gbt_gs = GridSearchCV(estimator=gbt_model, param_grid=gbt_param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')
gbt_gs.fit(df.drop(target, axis=1), df[target])
gbt_best = gbt_gs.best_estimator_
gbt_preds = gbt_best.predict(df.drop(target, axis=1))
gbt_mse = mean_squared_error(df[target], gbt_preds)

print("Model: Gradient Boosting Regressor")
print("Best Parameters: ", gbt_gs.best_params_)
print("MSE: ", gbt_mse)
print("Predictions: ", gbt_preds)
print("=" * 100)

"""##6) Log to the console the standard model metrics that apply."""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

# Split the data
p_train, p_test, q_train, q_test = train_test_split(p, q, test_size=0.3, random_state=0)

# Define models
models = [
    LinearRegression(),
    Ridge(alpha=0.1),
    Lasso(alpha=0.1),
    ElasticNet(alpha=0.1),
    RandomForestRegressor(n_estimators=100, random_state=0),
    XGBRegressor(n_estimators=100, objective='reg:squarederror', random_state=0),
    LGBMRegressor(n_estimators=100, random_state=0)
]

# Evaluation lists
rmse_list = []
mae_list = []

# Train and evaluate
for model in models:
    model.fit(p_train, q_train)
    q_pred = model.predict(p_test)
    rmse = np.sqrt(mean_squared_error(q_test, q_pred))
    mae = mean_absolute_error(q_test, q_pred)
    rmse_list.append(rmse)
    mae_list.append(mae)

# Print results
for i, model in enumerate(models):
    print(f"Model: {model.__class__.__name__}")
    print(f"RMSE: {rmse_list[i]:.3f}")
    print(f"MAE: {mae_list[i]:.3f}")
    print("=" * 30)